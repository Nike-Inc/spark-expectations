{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc224046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE INPUT WIDGETS FOR CONFIGURATION\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "widget_user = widgets.Text(\n",
    "    value='testuser',\n",
    "    placeholder='Type something',\n",
    "    description='user: ',\n",
    "    disabled=False,\n",
    "    style={'description_width': '100px'}    \n",
    ")\n",
    "\n",
    "widget_git_org = widgets.Text(\n",
    "    value='Nike-Inc',\n",
    "    placeholder='Type something',\n",
    "    description='git_org ',\n",
    "    disabled=False,\n",
    "    style={'description_width': '100px'}    \n",
    ")\n",
    "\n",
    "widget_catalog = widgets.Text(\n",
    "    value='spark_catalog',\n",
    "    placeholder='Type something',\n",
    "    description='catalog:',\n",
    "    disabled=False,\n",
    "    style={'description_width': '100px'}    \n",
    ")\n",
    "\n",
    "widget_schema = widgets.Text(\n",
    "    value='default',\n",
    "    placeholder='Type something',\n",
    "    description='schema:',\n",
    "    disabled=False,\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "widget_library_source = widgets.Combobox(\n",
    "    placeholder='Choose source',\n",
    "    options=['pypi', 'git'],\n",
    "    description='library_source:',\n",
    "    ensure_option=True,\n",
    "    value='git',\n",
    "    disabled=False,\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "widget_git_branch_or_commit = widgets.Text(\n",
    "    value='main',\n",
    "    placeholder='Type branch name or commit hash',\n",
    "    description='git_branch_or_commit:',\n",
    "    disabled=False,\n",
    "    style={'description_width': '150px'}\n",
    ")\n",
    "\n",
    "widget_override_version = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Override SE version',\n",
    "    disabled=False,\n",
    "    style={'description_width': '30px'}\n",
    ")\n",
    "\n",
    "hbox = widgets.HBox([\n",
    "    widget_user,\n",
    "    widget_catalog, \n",
    "    widget_schema,\n",
    "    widget_override_version, \n",
    "    widget_library_source, \n",
    "    widget_git_org,\n",
    "    widget_git_branch_or_commit\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display widgets\n",
    "display(hbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263fe506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract configuration values from widgets\n",
    "user = re.sub(r'[^a-zA-Z]', '', widget_user.value).lower()\n",
    "catalog = widget_catalog.value\n",
    "schema = widget_schema.value\n",
    "override_se_version = widget_override_version.value\n",
    "library = widget_library_source.value\n",
    "org = widget_git_org.value\n",
    "branch_or_commit = widget_git_branch_or_commit.value\n",
    "\n",
    "print(f\"User: {user}\")\n",
    "print(f\"Catalog: {catalog}\")\n",
    "print(f\"Schema: {schema}\")\n",
    "print(f\"Override SE Version: {override_se_version}\")\n",
    "print(f\"Library Source: {library}\")\n",
    "print(f\"Git Organization: {org}\")\n",
    "print(f\"Branch/Commit: {branch_or_commit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1874a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build configuration dictionary\n",
    "CONFIG = {\n",
    "    \"owner\": user,\n",
    "    \"catalog\": catalog,\n",
    "    \"schema\": schema,\n",
    "    \"user\": user,\n",
    "    \"product_id\": f\"se_{user}_product\",\n",
    "    \"rules_table\": f\"{catalog}.{schema}.se_{user}_rules\",\n",
    "    \"stats_table\": f\"{catalog}.{schema}.se_{user}_stats\",\n",
    "    \"customers_table\": f\"{catalog}.{schema}.se_{user}_customers\",\n",
    "    \"orders_table\": f\"{catalog}.{schema}.se_{user}_orders\",\n",
    "    \"products_table\": f\"{catalog}.{schema}.se_{user}_products\",\n",
    "    \"override_se_version\": override_se_version,\n",
    "    \"library\": library,\n",
    "    \"org\": org,\n",
    "    \"branch_or_commit\": branch_or_commit\n",
    "}\n",
    "\n",
    "config_df = pd.DataFrame(list(CONFIG.items()), columns=['Key', 'Value'])\n",
    "display(config_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89380ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display current Spark Expectations version\n",
    "from importlib.metadata import version\n",
    "print(f\"---- Current SparkExpectation Version: {version('spark-expectations')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919ba13",
   "metadata": {},
   "source": [
    "### Setting up Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE SPARK SESSION\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Expectations - DQ Pro Rules Test\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.0.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark session created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82adc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show existing databases and tables\n",
    "databases_df = spark.sql(\"SHOW DATABASES\")\n",
    "databases_df.show(truncate=False)\n",
    "\n",
    "tables_df = spark.sql(\"SHOW TABLES\")\n",
    "tables_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477697b3",
   "metadata": {},
   "source": [
    "### Cleanup Existing Tables and Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up existing tables and views from previous runs\n",
    "db_name = f\"{CONFIG['catalog']}.{CONFIG['schema']}\"\n",
    "pattern = f\"se_{CONFIG['user']}*\"\n",
    "\n",
    "# Set the current catalog\n",
    "spark.sql(f\"USE {CONFIG['catalog']}\")\n",
    "\n",
    "# Drop tables matching pattern\n",
    "tables_df = spark.sql(f\"SHOW TABLES IN {db_name} LIKE '{pattern}'\")\n",
    "tables_to_drop = [row for row in tables_df.collect() if not row[\"isTemporary\"]]\n",
    "\n",
    "if tables_to_drop:\n",
    "    print(f\"üßπ Found {len(tables_to_drop)} tables to drop.\")\n",
    "    for row in tables_to_drop:\n",
    "        table_name = row[\"tableName\"]\n",
    "        spark.sql(f\"DROP TABLE IF EXISTS {db_name}.{table_name}\")\n",
    "        print(f\"   ‚úì Dropped table: {db_name}.{table_name}\")\n",
    "else:\n",
    "    print(\"‚úÖ No tables to drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a19c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop views matching pattern\n",
    "views_df = spark.sql(f\"SHOW VIEWS in {db_name} LIKE '{pattern}'\")\n",
    "views_to_drop = views_df.collect()\n",
    "\n",
    "if views_to_drop:\n",
    "    print(f\"üßπ Found {len(views_to_drop)} views to drop.\")\n",
    "    for row in views_to_drop:\n",
    "        view_name = row[\"viewName\"]\n",
    "        spark.sql(f\"DROP VIEW IF EXISTS {view_name}\")\n",
    "        print(f\"   ‚úì Dropped view: {view_name}\")\n",
    "else:\n",
    "    print(\"‚úÖ No views to drop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2148a463",
   "metadata": {},
   "source": [
    "### Load Rules from YAML File\n",
    "Now let's load the comprehensive rules from `rules_all_types.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rules from YAML file\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "# Path to the rules file\n",
    "rules_file_path = \"/app/notebooks/resources/dqpro_rules.yaml\"\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(rules_file_path):\n",
    "    print(f\"‚ùå Rules file not found at: {rules_file_path}\")\n",
    "    print(\"Available files in resources:\")\n",
    "    for file in os.listdir(\"/app/notebooks/resources\"):\n",
    "        print(f\"  - {file}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Loading rules from: {rules_file_path}\")\n",
    "    \n",
    "    with open(rules_file_path, 'r') as file:\n",
    "        rules_yaml = yaml.safe_load(file)\n",
    "    \n",
    "    print(f\"üìã Loaded {len(rules_yaml)} rules from YAML file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d50e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert YAML rules to DataFrame format\n",
    "rules_data = []\n",
    "\n",
    "for rule_key, rule_value in rules_yaml.items():\n",
    "    rule_dict = {\n",
    "        \"product_id\": CONFIG[\"product_id\"],\n",
    "        \"table_name\": rule_value.get(\"table_name\", \"\"),\n",
    "        \"rule_type\": rule_value.get(\"rule_type\", \"\"),\n",
    "        \"rule\": rule_value.get(\"rule\", \"\"),\n",
    "        \"column_name\": rule_value.get(\"column_name\", \"\"),\n",
    "        \"expectation\": rule_value.get(\"expectation\", \"\"),\n",
    "        \"action_if_failed\": rule_value.get(\"action_if_failed\", \"\"),\n",
    "        \"tag\": rule_value.get(\"tag\", \"\"),\n",
    "        \"description\": rule_value.get(\"description\", \"\"),\n",
    "        \"enable_for_source_dq_validation\": rule_value.get(\"enable_for_source_dq_validation\", True),\n",
    "        \"enable_for_target_dq_validation\": rule_value.get(\"enable_for_target_dq_validation\", True),\n",
    "        \"is_active\": rule_value.get(\"is_active\", True),\n",
    "        \"enable_error_drop_alert\": rule_value.get(\"enable_error_drop_alert\", False),\n",
    "        \"error_drop_threshold\": rule_value.get(\"error_drop_threshold\", 0),\n",
    "        \"enable_querydq_custom_output\": rule_value.get(\"enable_querydq_custom_output\", False),\n",
    "        \"query_dq_delimiter\": rule_value.get(\"query_dq_delimiter\", None),\n",
    "        \"priority\": rule_value.get(\"priority\", \"medium\")\n",
    "    }\n",
    "    \n",
    "    # Update table names to use our config\n",
    "    if \"customers\" in rule_dict[\"table_name\"]:\n",
    "        rule_dict[\"table_name\"] = CONFIG[\"customers_table\"]\n",
    "    elif \"orders\" in rule_dict[\"table_name\"]:\n",
    "        rule_dict[\"table_name\"] = CONFIG[\"orders_table\"]\n",
    "    elif \"products\" in rule_dict[\"table_name\"]:\n",
    "        rule_dict[\"table_name\"] = CONFIG[\"products_table\"]\n",
    "    \n",
    "    rules_data.append(rule_dict)\n",
    "\n",
    "print(f\"‚úÖ Converted {len(rules_data)} rules to DataFrame format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dfd8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rules DataFrame and display summary\n",
    "rules_df = spark.createDataFrame(pd.DataFrame(rules_data))\n",
    "\n",
    "# Show summary of rules by type\n",
    "print(\"üìä Rules Summary by Type:\")\n",
    "rules_df.groupBy(\"rule_type\").count().show()\n",
    "\n",
    "print(\"\\nüìä Rules Summary by Action:\")\n",
    "rules_df.groupBy(\"action_if_failed\").count().show()\n",
    "\n",
    "print(\"\\nüìä Rules Summary by Tag:\")\n",
    "rules_df.groupBy(\"tag\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd535d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all DQ PRO rules \n",
    "print(\"üìã ALL DQ Rules loaded from yaml file:\")\n",
    "rules_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57761a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rules to Delta table\n",
    "rules_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(CONFIG['rules_table'])\n",
    "print(f\"‚úÖ Rules saved to table: {CONFIG['rules_table']}\")\n",
    "\n",
    "# Verify the table was created\n",
    "spark.sql(f\"SELECT COUNT(*) as rule_count FROM {CONFIG['rules_table']}\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
