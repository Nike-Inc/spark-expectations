### Effortlessly Explore Spark Expectations on Example Dataset with Automated Setup in Databricks 

This section provides instructions on how to set up a sample notebook in the Databricks environment to investigate, comprehend, and conduct a feasibility study on the Spark Expectations framework.

#### Prerequisite:

1. Recommended Databricks run time environment for better experience - DBS 11.0 and above
2. Please install the Kafka jar using the path `dbfs:/kafka-jars/databricks-shaded-strimzi-kafka-oauth-client-1.1.jar`, If the jar is not available in the dbfs location, please raise a ticket with Platform team to add the jar to your workspace
3. Please follow the steps provided [here](TODO) to integrate and clone repo from git Databricks
4. Please follow the steps to create the webhook-hook URL for team-specific channel [here](TODO)